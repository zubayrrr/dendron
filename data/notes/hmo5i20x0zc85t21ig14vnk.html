<h1 id="mapreduce-in-python"><a aria-hidden="true" class="anchor-heading" href="#mapreduce-in-python"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>MapReduce in Python</h1>
<ul>
<li>Areas: <a title="Private" style="color: brown" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank">devlog.Data Engineering (Private)</a></li>
</ul>
<hr>
<h2 id="simulating-map-and-reduce-using-python-and-bash-scripts"><a aria-hidden="true" class="anchor-heading" href="#simulating-map-and-reduce-using-python-and-bash-scripts"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Simulating Map and Reduce using Python and Bash scripts</h2>
<p>Source: <a href="https://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/">https://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/</a></p>
<p>There are several methods to program a Hadoop MapReduce. The most direct and lowest level is using the Java Hadoop API or the C++ Pipes library.</p>
<p>Many users prefer the flexibility of the Streams Interface that allows a variety of programming language to be used.</p>
<p>This method will work with any program that can read and write TEXT DATA to <a href="/notes/n4ernfsrloq7zjrscm8t5rc">Redirecting stdin &#x26; stderr</a> and <a href="/notes/do68y261xeu98bpq3vl5cn9">stdout</a>.</p>
<h3 id="developing-a-hadoop-streaming-word-counting-application"><a aria-hidden="true" class="anchor-heading" href="#developing-a-hadoop-streaming-word-counting-application"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Developing a Hadoop Streaming word counting application.</h3>
<ul>
<li>pymapper.py - a python word count mapper</li>
<li>shuffer.sh - a simulated shuffle step using bash script</li>
<li>pyreducer.py - a python word count reducer</li>
</ul>
<!-- end list -->
<pre><code>#!/usr/bin/env python
"""pymapper.py"""

import sys

# input comes from STDIN (standard input)
for line in sys.stdin:
    # remove leading and trailing whitespace
    line = line.strip()
    # split the line into words
    words = line.split()
    # increase counters
    for word in words:
        # write the results to STDOUT (standard output);
        # what we output here will be the input for the
        # Reduce step, i.e. the input for reducer.py
        #
        # tab-delimited; the trivial word count is 1
        print '%s\t%s' % (word, 1)

#!/bin/bash
# shuffle.sh
sort -k1,1

#!/usr/bin/env python
"""pyreducer.py"""

from operator import itemgetter
import sys

current_word = None
current_count = 0
word = None

# input comes from STDIN
for line in sys.stdin:
    # remove leading and trailing whitespace
    line = line.strip()

    # parse the input we got from mapper.py
    word, count = line.split('\t', 1)

    # convert count (currently a string) to int
    try:
        count = int(count)
    except ValueError:
        # count was not a number, so silently
        # ignore/discard this line
        continue

    # this IF-switch only works because Hadoop sorts map output
    # by key (here: word) before it is passed to the reducer
    if current_word == word:
        current_count += count
    else:
        if current_word:
            # write result to STDOUT
            print ('%s\t%s' % (current_word, current_count))
        current_count = count
        current_word = word

# do not forget to output the last word if needed!
if current_word == word:
    print ('%s\t%s' % (current_word, current_count))
</code></pre>
<p>1. Run the <code>pymapper.py</code> with some simple data and change the input words to key value pairs.</p>
<pre><code>echo "see spot run run spot run see the cat" | ./pymapper.py
</code></pre>
<p>2. Sort the data passed through <code>pymapper.py</code></p>
<pre><code>echo "see spot run run spot run see the cat" | ./pymapper.py | ./shuffle.sh
</code></pre>
<p>3. Add the reducer stage and count all the same keys</p>
<pre><code>echo "see spot run run spot run see the cat" | ./pymapper.py | ./shuffle.sh | ./pyreducer.py
</code></pre>