<h1 id="rdd"><a aria-hidden="true" class="anchor-heading" href="#rdd"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>RDD</h1>
<ul>
<li>Areas: <a href="/notes/f2kecna72pmc7re3wh1ugk4">Apache Spark</a></li>
</ul>
<hr>
<p>Resilient Distributed Datasets</p>
<p>Spark Core is embedded with RDDs, an immutable fault-tolerant(like files in <a href="/notes/kdddo1f7ltfsuwhexj4s535">HDFS</a>), distributed collection of objects that can be operated on in parallel.</p>
<p>It where the data will be loaded(or existing for processing), it can exist for shorter amount of time.</p>
<ul>
<li>RDDs are the fundamental units of data in Apache Spark that are split into partitions and can be executed on different nodes of a cluster. Implicit, lazy in nature, created whenever you use a method of SparkContext or when you do a transformation on an existing RDD or a dataset.</li>
<li>Each dataset in an RDD is divided into logical memory partitions that may be computed on different nodes of a cluster.</li>
<li>By default every RDD has 2 partitions, which can be customized while creating RDDs.</li>
<li>The more partitions you've the better the parallel processing.</li>
<li>RDDs are automatically split into partitions and can be executed upon different nodes by different taks in parallel, in-memory.</li>
</ul>
<p>There are mainly two operations that can be peformed on an RDD</p>
<h3 id="transformation"><a aria-hidden="true" class="anchor-heading" href="#transformation"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Transformation</h3>
<ul>
<li>These are operations (such as map, filter, join, union) that are peformed on an RDD that yields as new RDD containing the result.</li>
<li>They return a pointer to a new RDD. The original RDD cannot be changed. Spark is "lazy" and nothing will be executed unless an action is invoked.</li>
<li>It isn't necessarily reproducing a new set of data or RDD, but is a new "state". Think of it as step(s) in a program telling Spark how to get new data and what to do with it.</li>
<li><strong>Resilience</strong> is the ability to retrace steps from the beginning.</li>
</ul>
<h3 id="actions"><a aria-hidden="true" class="anchor-heading" href="#actions"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Actions</h3>
<ul>
<li>These are operations (reduce, first, count, collect, count, take save-as) that return a value after running a computation on an RDD.</li>
<li>They return values and force the transformations to actually take place.</li>
</ul>
<p>See also: <a title="Private" style="color: brown" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank">DAG (Private)</a></p>
<hr>
<strong>Backlinks</strong>
<ul>
<li><a href="/notes/f2kecna72pmc7re3wh1ugk4">Apache Spark</a></li>
<li><a href="/notes/s5t9uscswvpo3p6gebui1ea">Big Data</a></li>
<li><a href="/notes/bojmgq30yfxpn44hgo0ofcf">DAG</a></li>
<li><a href="/notes/iholoz516z4p3yeo29eldm4">Spark Architecture</a></li>
</ul>