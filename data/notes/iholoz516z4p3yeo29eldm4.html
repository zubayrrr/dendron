<h1 id="spark-architecture"><a aria-hidden="true" class="anchor-heading" href="#spark-architecture"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Spark Architecture</h1>
<ul>
<li>Areas: <a href="/notes/f2kecna72pmc7re3wh1ugk4">Apache Spark</a></li>
</ul>
<hr>
<p>Apache Spark uses a master-slave(technically, although it can also run in standalone mode) architecture that consists of a driver, that runs on a master node and multiple executors which run across the worker nodes in the cluster.</p>
<p>It can work with different clustering technologies such as Apache Mesos, <a href="/notes/6k7g4x7ws565lditv1n8hxm">YARN</a>. It can also work as standalone.</p>
<p>Master Node has a driver program; this driver program internally has SparkContext.</p>
<p>The Spark code behaves as a driver program and creates a SparkContext, which is gateway to all the Spark functionalities.</p>
<p>Driver program interacts with cluster manager(SparkContext, the entry point, takes the request to the cluster manager).</p>
<p>Cluster manager in terms of YARN is the <code>ResourceManager</code></p>
<p>Spark application runs as independent set of processes on a cluster.</p>
<p>The driver program and SparkContext takes care of the job execution within the cluster.</p>
<p>A job is split into multiple tasks that are distributed over the worker node.</p>
<p>When an <a href="/notes/2vn2g9mhmi624b83rl5se0k">RDD</a> is created in SparkContext, it can be distributed across various nodes.</p>
<p>Worker nodes are slaves that run different tasks.</p>
<hr>
<p>Spark Architecture is based on 2 important abstractions:</p>
<h3 id="rdd"><a aria-hidden="true" class="anchor-heading" href="#rdd"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a><a href="/notes/2vn2g9mhmi624b83rl5se0k">RDD</a></h3>
<p>Resilient Distributed Datasets</p>
<p>Spark Core is embedded with RDDs, an immutable fault-tolerant(like files in HDFS), distributed collection of objects that can be operated on in parallel.</p>
<p>It where the data will be loaded(or existing for processing), it can exist for shorter amount of time.</p>
<ul>
<li>RDDs are the fundamental units of data in Apache Spark that are split into partitions and can be executed on different nodes of a cluster. Implicit, lazy in nature, created whenever you use a method of SparkContext or when you do a transformation on an existing RDD or a dataset.</li>
<li>Each dataset in an RDD is divided into logical memory partitions that may be computed on different nodes of a cluster.</li>
<li>By default every RDD has 2 partitions, which can be customized while creating RDDs.</li>
<li>The more partitions you've the better the parallel processing.</li>
<li>RDDs are automatically split into partitions and can be executed upon different nodes by different taks in parallel, in-memory.</li>
</ul>
<p>There are mainly two operations that can be peformed on an RDD</p>
<h3 id="transformation"><a aria-hidden="true" class="anchor-heading" href="#transformation"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Transformation</h3>
<ul>
<li>These are operations (such as map, filter, join, union) that are peformed on an RDD that yields as new RDD containing the result.</li>
<li>They return a pointer to a new RDD. The original RDD cannot be changed. Spark is "lazy" and nothing will be executed unless an action is invoked.</li>
<li>It isn't necessarily reproducing a new set of data or RDD, but is a new "state". Think of it as step(s) in a program telling Spark how to get new data and what to do with it.</li>
<li><strong>Resilience</strong> is the ability to retrace steps from the beginning.</li>
</ul>
<h3 id="actions"><a aria-hidden="true" class="anchor-heading" href="#actions"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Actions</h3>
<ul>
<li>These are operations (reduce, first, count, collect, count, take save-as) that return a value after running a computation on an RDD.</li>
<li>They return values and force the transformations to actually take place.</li>
</ul>
<p>See also: <a title="Private" style="color: brown" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank">DAG (Private)</a>, <a title="Private" style="color: brown" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank">Spark Cluster Managers (Private)</a></p>