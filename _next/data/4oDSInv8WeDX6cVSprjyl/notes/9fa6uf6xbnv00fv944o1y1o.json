{"pageProps":{"note":{"id":"9fa6uf6xbnv00fv944o1y1o","title":"Prometheus","desc":"","updated":1656157185510,"created":1653569037304,"custom":{},"fname":"devlog.prometheus","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Dendron"},"contentHash":"e198c932040cd4f2cf5f6869c4e0ec32","links":[{"type":"wiki","from":{"fname":"devlog.prometheus","id":"9fa6uf6xbnv00fv944o1y1o","vaultName":"Dendron"},"value":"devlog.kubernetes","alias":"devlog.kubernetes","position":{"start":{"line":4,"column":70,"offset":184},"end":{"line":4,"column":91,"offset":205},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.kubernetes"}},{"type":"wiki","from":{"fname":"devlog.prometheus","id":"9fa6uf6xbnv00fv944o1y1o","vaultName":"Dendron"},"value":"devlog.docker swarm","alias":"devlog.docker swarm","position":{"start":{"line":4,"column":93,"offset":207},"end":{"line":4,"column":116,"offset":230},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.docker swarm"}},{"type":"wiki","from":{"fname":"devlog.prometheus","id":"9fa6uf6xbnv00fv944o1y1o","vaultName":"Dendron"},"value":"devlog.Linux","alias":"devlog.Linux","position":{"start":{"line":26,"column":21,"offset":1460},"end":{"line":26,"column":37,"offset":1476},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.Linux"}},{"type":"wiki","from":{"fname":"devlog.prometheus","id":"9fa6uf6xbnv00fv944o1y1o","vaultName":"Dendron"},"value":"devlog.apache","alias":"devlog.apache","position":{"start":{"line":26,"column":75,"offset":1514},"end":{"line":26,"column":92,"offset":1531},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.apache"}},{"type":"wiki","from":{"fname":"devlog.prometheus","id":"9fa6uf6xbnv00fv944o1y1o","vaultName":"Dendron"},"value":"devlog.MySQL","alias":"devlog.MySQL","position":{"start":{"line":62,"column":64,"offset":3262},"end":{"line":62,"column":80,"offset":3278},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.MySQL"}},{"type":"wiki","from":{"fname":"devlog.prometheus","id":"9fa6uf6xbnv00fv944o1y1o","vaultName":"Dendron"},"value":"devlog.Elasticsearch","alias":"devlog.Elasticsearch","position":{"start":{"line":62,"column":82,"offset":3280},"end":{"line":62,"column":106,"offset":3304},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.Elasticsearch"}},{"type":"wiki","from":{"fname":"devlog.prometheus","id":"9fa6uf6xbnv00fv944o1y1o","vaultName":"Dendron"},"value":"devlog.Linux","alias":"devlog.Linux","position":{"start":{"line":62,"column":108,"offset":3306},"end":{"line":62,"column":124,"offset":3322},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.Linux"}},{"type":"wiki","from":{"fname":"devlog.prometheus","id":"9fa6uf6xbnv00fv944o1y1o","vaultName":"Dendron"},"value":"devlog.build automation","alias":"Build Tools","position":{"start":{"line":62,"column":134,"offset":3332},"end":{"line":62,"column":173,"offset":3371},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.build automation"}},{"type":"wiki","from":{"fname":"devlog.prometheus","id":"9fa6uf6xbnv00fv944o1y1o","vaultName":"Dendron"},"value":"devlog.mysql","alias":"devlog.mysql","position":{"start":{"line":70,"column":24,"offset":3733},"end":{"line":70,"column":40,"offset":3749},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.mysql"}},{"type":"wiki","from":{"fname":"devlog.prometheus","id":"9fa6uf6xbnv00fv944o1y1o","vaultName":"Dendron"},"value":"devlog.kubernetes","alias":"devlog.kubernetes","position":{"start":{"line":70,"column":56,"offset":3765},"end":{"line":70,"column":77,"offset":3786},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.kubernetes"}},{"type":"wiki","from":{"fname":"devlog.prometheus","id":"9fa6uf6xbnv00fv944o1y1o","vaultName":"Dendron"},"value":"devlog.AWS CloudWatch","alias":"devlog.AWS CloudWatch","position":{"start":{"line":84,"column":30,"offset":4502},"end":{"line":84,"column":55,"offset":4527},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.AWS CloudWatch"}},{"type":"wiki","from":{"fname":"devlog.prometheus","id":"9fa6uf6xbnv00fv944o1y1o","vaultName":"Dendron"},"value":"devlog.New Relic","alias":"devlog.New Relic","position":{"start":{"line":84,"column":59,"offset":4531},"end":{"line":84,"column":79,"offset":4551},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.New Relic"}},{"from":{"fname":"areas.devops","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":157,"column":3,"offset":4633},"end":{"line":157,"column":24,"offset":4654},"indent":[]},"value":"devlog.Prometheus","alias":"devlog.Prometheus"},{"from":{"fname":"devlog.devops interview questions","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":11,"column":40,"offset":632},"end":{"line":11,"column":61,"offset":653},"indent":[]},"value":"devlog.prometheus","alias":"devlog.prometheus"},{"from":{"fname":"devlog.devops interview questions","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":145,"column":3,"offset":6808},"end":{"line":145,"column":24,"offset":6829},"indent":[]},"value":"devlog.prometheus","alias":"devlog.prometheus"},{"from":{"fname":"devlog.devops interview questions","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":359,"column":5,"offset":16497},"end":{"line":359,"column":26,"offset":16518},"indent":[]},"value":"devlog.prometheus","alias":"devlog.prometheus"},{"from":{"fname":"devlog.devops interview questions","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":13,"column":1,"offset":676},"end":{"line":13,"column":40,"offset":715},"indent":[]},"value":"devlog.prometheus"},{"from":{"fname":"devlog.kubernetes","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":283,"column":52,"offset":14291},"end":{"line":283,"column":73,"offset":14312},"indent":[]},"value":"devlog.Prometheus","alias":"devlog.Prometheus"}],"anchors":{"prometheus-architecture":{"type":"header","text":"Prometheus Architecture","value":"prometheus-architecture","line":16,"column":0,"depth":1},"prometheus-server":{"type":"header","text":"Prometheus Server","value":"prometheus-server","line":18,"column":0,"depth":2},"targets-and-metrics":{"type":"header","text":"Targets and Metrics","value":"targets-and-metrics","line":28,"column":0,"depth":2},"getting-metrics":{"type":"header","text":"Getting metrics","value":"getting-metrics","line":52,"column":0,"depth":2},"push-based-vs-pull-based":{"type":"header","text":"Push based VS Pull based","value":"push-based-vs-pull-based","line":88,"column":0,"depth":2},"configuring-prometheus":{"type":"header","text":"Configuring Prometheus","value":"configuring-prometheus","line":107,"column":0,"depth":2},"alertmanager":{"type":"header","text":"AlertManager","value":"alertmanager","line":126,"column":0,"depth":2},"prometheus-data-storage":{"type":"header","text":"Prometheus Data Storage","value":"prometheus-data-storage","line":134,"column":0,"depth":2},"promql":{"type":"header","text":"PromQL","value":"promql","line":142,"column":0,"depth":2},"sailent-characteristics-of-prometheus":{"type":"header","text":"Sailent Characteristics of Prometheus","value":"sailent-characteristics-of-prometheus","line":166,"column":0,"depth":2},"prometheus-federation":{"type":"header","text":"Prometheus Federation","value":"prometheus-federation","line":180,"column":0,"depth":2},"prometheus-with-docker--kubernetes":{"type":"header","text":"Prometheus with Docker & Kubernetes","value":"prometheus-with-docker--kubernetes","line":186,"column":0,"depth":2}},"children":[],"parent":"9gtn7g40cvqui0sifl1s7t5","data":{}},"body":"<h1 id=\"prometheus\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#prometheus\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Prometheus</h1>\n<p>Prometheus is a monitoring tool. It collects metrics and stores it with which we can make dashboards and alerts.</p>\n<p>It was created to monitor highly dynamic container environments like <a href=\"/notes/gbeh61d6hvbmxxy63chp81b\">Kubernetes</a>, <a href=\"/notes/q5su7hd0um6fz4hbue7gzpr\">Docker Swarm</a> etc. It can also be used in traditional non-container infrastructure.</p>\n<p>Typically you've many servers that run containerized applications, hundreds of different processes running on that infrastructure which are all interconnected. To get insights on this infrastructure such as errors, latency etc.</p>\n<p>To make it easier for us to debug these system and fix them without much downtime, we'll use something like Prometheus, that will constantly monitor all the services/resources, alerts the maintainers as soon as anything goes wrong. <strong>In fact it can identify problems before they even occur</strong> and notify the maintainers so the failures can be prevented.</p>\n<h1 id=\"prometheus-architecture\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#prometheus-architecture\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Prometheus Architecture</h1>\n<h2 id=\"prometheus-server\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#prometheus-server\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Prometheus Server</h2>\n<p>This is what does the actual monitoring.</p>\n<p>It constitutes of three components:</p>\n<ul>\n<li>Time Series DB - stores metrics data, no. of exceptions.</li>\n<li>Data Retrieval Worker - responsible for pulling metrics from applications/services/servers - target resources and pushing them to the Time series DB.</li>\n<li>HTTP Server - Accepts PromQL queries for that stored data. Web server API is used to display data in a dashboard or UI - either Prometheus UI or Grafana etc.</li>\n</ul>\n<h2 id=\"targets-and-metrics\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#targets-and-metrics\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Targets and Metrics</h2>\n<p>What does Prometheus monitor?</p>\n<p>It can be an entire <a href=\"/notes/owoutsv5dicylguol2odc3e\">Linux</a> server, Windows server, a standalone <a href=\"/notes/hquxlv96i7vchw88x1zr8hk\">Apache</a> server, single application or service. These are called as <strong>Targets</strong>.</p>\n<p>Each target has unit of monitoring:</p>\n<ul>\n<li>For a Linux server it could be current CPU usage, memory usage, disk space usage.</li>\n<li>For an application - No. of exceptions, requests, request duration.</li>\n</ul>\n<p>A unit that you'd want to monitor for a target is called a <strong>Metric</strong>.\nThey're what gets stored in Prometheus DB component. Prometheus defines human readable, text based format for the metrics. Metric entries or data has <code>TYPE</code> and <code>HELP</code> attributes to increase it's readability.</p>\n<p><code>HELP</code> is basically description of the metric.\n<code>TYPE</code> is one of three metric types:</p>\n<ul>\n<li><code>Counter</code>\n<ul>\n<li>For how many times x happened</li>\n</ul>\n</li>\n<li><code>Gauge</code>\n<ul>\n<li>For a metric that can go up and down. Eg: Current value of x now?</li>\n</ul>\n</li>\n<li><code>Histogram</code>\n<ul>\n<li>For tracking how long something took or how big something was(like the size of a request).</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"getting-metrics\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#getting-metrics\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Getting metrics</h2>\n<p>How does Prometheus collect metrics from the targets?</p>\n<p><strong>Pulling</strong></p>\n<p>Your application(regardless of technology) will have to expose a metrics HTTP endpoint and Prometheus will scrape from the endpoint. By default is is: <code>hostaddress/metrics</code>.</p>\n<p>Data available in the <code>/metrics</code> endpoint should be in the correct format that Prometheus understands.</p>\n<p>Some servers expose Prometheus endpoints by default so you don't really have to do extra work for it. But many services don't have native Prometheus endpoints in which case you'd need an <strong>Exporter</strong></p>\n<p><strong>Exporter</strong></p>\n<p>It basically a script/service that fetches metrics from your target and converts them in format Prometheus understands and exposes it's converted data at it's own <code>/metrics</code> endpoint where Prometheus can scrape them.</p>\n<p>Prometheus has a list of exporters for different services like <a href=\"/notes/ypszfixe0p3s5k0inqs5g08\">MySql</a>, <a href=\"/notes/boyz5i8gtwc9aoj4zfz556y\">Elasticsearch</a>, <a href=\"/notes/owoutsv5dicylguol2odc3e\">Linux</a> servers, <a href=\"/notes/qcaw5ht4vcnucydq104gh7v\">Build Tools</a>, Cloud Platforms and so on.</p>\n<p>If you want to monitor a Linux server, see: <a href=\"https://prometheus.io/docs/guides/node-exporter/\">Monitoring Linux host metrics with the Node Exporter | Prometheus</a></p>\n<p><img src=\"https://res.cloudinary.com/zubayr/image/upload/v1656150261/wiki/xfe8c37gmzogdoin3wtx.png\"></p>\n<p>Exporters are also available as Docker images. SO</p>\n<p>If you want to monitor <a href=\"/notes/ypszfixe0p3s5k0inqs5g08\">MySql</a> container in a <a href=\"/notes/gbeh61d6hvbmxxy63chp81b\">Kubernetes</a> cluster, you can deploy  a sidecar container of MySQL exporter that will run inside the pod with MySQL container, connect to it and start sending MySQL metrics for Prometheus and making them available at itâ€™s own <code>/metrics</code> endpoint.</p>\n<p><strong>Monitoring  your own applications?</strong></p>\n<ul>\n<li>\n<p>How many requests your applications are receiving.</p>\n</li>\n<li>\n<p>How many exceptions are occurring.</p>\n</li>\n<li>\n<p>How many server resources your application is using.</p>\n<p> For this you can use Client Libraries for different languages using which you can expose <code>/metrics</code> endpoint for metrics that are relevant to you.\n<a href=\"https://prometheus.io/docs/instrumenting/clientlibs/\">Client libraries | Prometheus</a></p>\n</li>\n</ul>\n<h2 id=\"push-based-vs-pull-based\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#push-based-vs-pull-based\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Push based VS Pull based</h2>\n<p>Most monitoring systems like <a href=\"/notes/42qbhsb3tdd4z7w7ynfmjj1\">AWS CloudWatch</a> or <a href=\"/notes/g8txkrlv8lggex7u6372sd1\">New Relic</a> etc use a Push system. Applications and servers are responsible for pushing their metric data to a centralized collection platform of that monitoring tool.</p>\n<p>In large microservices based system this approach can create a bottleneck for your infrastructure as all of these microservices constantly make push request to your monitoring tool thus flooding your system.</p>\n<p>Plus, youâ€™ll also need to install additional software(daemons) on each of your targets to push the metrics to the monitoring server. In contrast with Prometheus which only requires a scraping endpoint.</p>\n<p>Multiple Prometheus instances can collect/pull metrics. Using pull, Prometheus can easily detect whether a service is up and running or not.</p>\n<p>Pushing can be ambiguous when checking if the service is up or not when compared to pull mechanism. Because there can be many reasons for a push request to fail. </p>\n<p><strong>Pushing</strong></p>\n<p>Pushgateway can be utilized when a target only runs for a short time.\nEg: A batch job, scheduled job etc. For such jobs, Prometheus offers Pushgateway component. So these services can push metrics directly to Prometheus DB.</p>\n<p><img src=\"https://res.cloudinary.com/zubayr/image/upload/v1655885235/wiki/yguspabejdgcr4qbzegm.png\"></p>\n<h2 id=\"configuring-prometheus\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#configuring-prometheus\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Configuring Prometheus</h2>\n<p><code>prometheus.yaml</code> file contains all the info needed for Prometheus to know what(targets) to scrape and when(intervals). </p>\n<p>Prometheus then uses <strong>Service Discovery</strong>  mechanism to find those target endpoints.</p>\n<p>You can find the sample config files with default values which comes with your first Prometheus installation.</p>\n<p><img src=\"https://res.cloudinary.com/zubayr/image/upload/v1656153062/wiki/p2l9ubydx8h1viv4pafn.png\"></p>\n<p>Under <code>global:</code> you define how often Prometheus will scrape itâ€™s targets.</p>\n<p>Rules are for aggregating metric values or creating alerts when conditions\nare met.</p>\n<p><code>scrape_configs:</code> define what resources Prometheus monitors; essentially targets. You can define your own jobs and default values for each job(overwrite global interval values).</p>\n<p>Since Prometheus has itâ€™s own <code>/metrics</code> endpoint, it can monitor itâ€™s own health.</p>\n<h2 id=\"alertmanager\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#alertmanager\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>AlertManager</h2>\n<p>How does Prometheus trigger alerts that are defined by rules in <code>prometheus.yaml</code> and who receives these alerts?</p>\n<p>Prometheus has a component called AlertManger that is responsible for firing alerts via different channels (Emails, Slack channel or other notification clients).</p>\n<p>Prometheus server will read alert rules and if the conditions under rules is met an alert is fired. </p>\n<h2 id=\"prometheus-data-storage\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#prometheus-data-storage\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Prometheus Data Storage</h2>\n<p>Where does Prometheus store all the data that it collects/aggregates? How can other systems use this data?</p>\n<p>Prometheus stores metric data on disks, includes Local on disk <strong>Time Series DB</strong> but also optionally integrates with remote storage system. It is stored in custom Time Series format. Because of this you cannot directly write this data on a relational DB or something else.</p>\n<p>Once collected, Prometheus lets you query the data through itâ€™s server API using itâ€™s query language called <strong>PromQL</strong>.</p>\n<h2 id=\"promql\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#promql\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>PromQL</h2>\n<p>You can use Prometheus dashboard UI to ask Prometheus server via PromQL to for example show the status of a target right now.</p>\n<p>Or use more powerful data visualization tools like <strong>Grafana</strong> to display the data which uses PromQL under the hood to get data out of Prometheus .</p>\n<p>Example PromQL query to:</p>\n<p>Query all HTTP status codes except <code>4xx</code> ones</p>\n<pre class=\"language-sql\"><code class=\"language-sql\">http_requests_total{<span class=\"token keyword\">status</span><span class=\"token operator\">!</span><span class=\"token operator\">~</span><span class=\"token string\">\"4..\"</span>}\n</code></pre>\n<p>This query does some subquery:</p>\n<p>Returns the 5 minute rate of the <em>http_requests_total</em> metric for the past 30 minutes.</p>\n<pre class=\"language-sql\"><code class=\"language-sql\">rate<span class=\"token punctuation\">(</span>http_requests_total<span class=\"token punctuation\">[</span><span class=\"token number\">5</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">[</span><span class=\"token number\">30</span>m:<span class=\"token punctuation\">]</span>\n</code></pre>\n<p><img src=\"https://res.cloudinary.com/zubayr/image/upload/v1656153983/wiki/qu5c4x2hrwuozqeqebxy.png\"></p>\n<h2 id=\"sailent-characteristics-of-prometheus\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#sailent-characteristics-of-prometheus\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Sailent Characteristics of Prometheus</h2>\n<p>It is designed to be reliable even when other systems have an outage so you can diagnose the problems and fix them.</p>\n<p>Each Prometheus server is standalone and self-contained. It doesnâ€™t depend on network storage or other remote services. It is meant to be still working when other parts of the infrastructure are broken.</p>\n<p>It doesnâ€™t require extensive setup needed.</p>\n<p><strong>Drawbacks:</strong></p>\n<p>It can be difficult to scale, when you have hundreds of servers that you want to use multiple Prometheus instances for aggregation of metrics setting them up can get complicated.</p>\n<p>A workaround this would be to increase the capacity of your Prometheus server, limit the number of metrics Prometheus collects from applications.</p>\n<h2 id=\"prometheus-federation\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#prometheus-federation\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Prometheus Federation</h2>\n<p>To scale monitoring with scalable cloud apps.</p>\n<p>Prometheus Federation allows one Prometheus server to scrape data from another Prometheus server. This will allow you to scale your Prometheus setup with your multi-node applications.</p>\n<h2 id=\"prometheus-with-docker--kubernetes\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#prometheus-with-docker--kubernetes\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Prometheus with Docker &#x26; Kubernetes</h2>\n<p>It is fully compatible with both.</p>\n<p>Prometheus components are available as Docker images and therefore can be deployed on Kubernetes or other container environments.</p>\n<p>It provides monitoring of K8s Cluster Node Resource out of the box! Once deployed on K8s, it starts gather metrics data on each Kubernetes node server without any extra configuration.</p>\n<hr>\n<strong>Backlinks</strong>\n<ul>\n<li><a href=\"/notes/522ww47pqvt6y0yj8zparmy\">DevOps</a></li>\n<li><a href=\"/notes/5eybx5vd339tjnkglx8igde\">Devops Interview Questions</a></li>\n<li><a href=\"/notes/gbeh61d6hvbmxxy63chp81b\">Kubernetes</a></li>\n</ul>","noteIndex":{"id":"3nfl4nvv516muyzozhcwrw8","title":"/root","desc":"","updated":1655559901157,"created":1637610830605,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Dendron"},"contentHash":"581715455a6f0f7a699209e8521b4acf","links":[{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"archive.about","alias":"my","position":{"start":{"line":4,"column":9,"offset":37},"end":{"line":4,"column":29,"offset":57},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"archive.about"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"tags.areas","alias":"#areas","position":{"start":{"line":20,"column":111,"offset":1051},"end":{"line":20,"column":117,"offset":1057},"indent":[]},"xvault":false,"to":{"fname":"tags.areas"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"tags.areas","alias":"#areas","position":{"start":{"line":21,"column":3,"offset":1198},"end":{"line":21,"column":9,"offset":1204},"indent":[]},"xvault":false,"to":{"fname":"tags.areas"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"swipes","alias":"swipes","position":{"start":{"line":27,"column":3,"offset":1724},"end":{"line":27,"column":13,"offset":1734},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"swipes"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"swipes.quotes","alias":"quotes","position":{"start":{"line":27,"column":48,"offset":1769},"end":{"line":27,"column":72,"offset":1793},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"swipes.quotes"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"swipes.excerpts","alias":"excerpts","position":{"start":{"line":27,"column":74,"offset":1795},"end":{"line":27,"column":102,"offset":1823},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"swipes.excerpts"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"swipes.sayings","alias":"sayings","position":{"start":{"line":27,"column":104,"offset":1825},"end":{"line":27,"column":130,"offset":1851},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"swipes.sayings"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"swipes.phrases","alias":"phrases","position":{"start":{"line":27,"column":132,"offset":1853},"end":{"line":27,"column":158,"offset":1879},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"swipes.phrases"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"resources.people","alias":"others","position":{"start":{"line":27,"column":214,"offset":1935},"end":{"line":27,"column":241,"offset":1962},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"resources.people"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"inbox.webmark","alias":"webmark","position":{"start":{"line":31,"column":235,"offset":2463},"end":{"line":31,"column":260,"offset":2488},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"inbox.webmark"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"slipbox.Ontology","alias":"slipbox.Ontology","position":{"start":{"line":55,"column":3,"offset":3735},"end":{"line":55,"column":23,"offset":3755},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"slipbox.Ontology"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"archive.about","alias":"About me","position":{"start":{"line":60,"column":3,"offset":3963},"end":{"line":60,"column":29,"offset":3989},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"archive.about"}}],"anchors":{"welcome-to-noetic-noggin":{"type":"header","text":"Welcome to Noetic Noggin","value":"welcome-to-noetic-noggin","line":8,"column":0,"depth":1},"principles":{"type":"header","text":"Principles","value":"principles","line":18,"column":0,"depth":2},"all-notes-should-be-relative-to-me":{"type":"header","text":"All notes should be relative to me.","value":"all-notes-should-be-relative-to-me","line":20,"column":0,"depth":3},"gotta-capture-em-all":{"type":"header","text":"Gotta capture 'em all","value":"gotta-capture-em-all","line":30,"column":0,"depth":3},"dont-force-evolution":{"type":"header","text":"Don't force evolution","value":"dont-force-evolution","line":40,"column":0,"depth":3},"noise--signal":{"type":"header","text":"Noise & Signal","value":"noise--signal","line":45,"column":0,"depth":3},"why-do-any-of-this":{"type":"header","text":"Why do any of this?","value":"why-do-any-of-this","line":50,"column":0,"depth":3},"structure-of-this-wiki":{"type":"header","text":"Structure of this wiki","value":"structure-of-this-wiki","line":59,"column":0,"depth":2},"quicklinks":{"type":"header","text":"Quicklinks","value":"quicklinks","line":64,"column":0,"depth":2}},"children":["0yay2om15bsg2li2p6qgux7","05c4nnjqa92zx11ld6o0ytn","9gtn7g40cvqui0sifl1s7t5","ftbd1hknsd3ocd7jao26tn3","a1kmkdbpclaz5p6sykaw6kc","z121gkmqfo09m8r7jgnpfgn","gkqrr7xbt18xhi93dmjrwzj","ja2x4lrgejr9o9wvit0bd0d","luv39odkfibx3wdosvigwvy","vtvk3bi6o72w58oima9xzf3","yy652kvqrkfn9ipk07m40h4"],"parent":null,"data":{},"body":"\n# Welcome to Noetic Noggin\n\nThis is [[my|archive.about]] personal wiki and a commonplace book; notes by me, for me.\n\nðŸš§ Permanently under construction ðŸš§\n\n![](https://res.cloudinary.com/zubayr/image/upload/v1658499909/wiki/ajevkuyebljlxiblyst2.png)\n\nThis wiki was made possible with [dendron.so](https://dendron.so) and [obisidian.md](https://obsidian.md). Stored on [Github Repository](https://github.com/zubayrrr/dendron) and hosted on [Netlify](https://netlify.com) for free.\n\n## Principles\n\n### All notes should be relative to me.\n\n- All notes in principle are written for me; what I know about a subject, how I feel about a particular thing.\n- Opinions are fine as long as I feel strong epistemic confidence in the given opinion.\n- Don't over explain a note if it's not necessary, remember, these notes are for you and are relative to whatever knowledge you posses about the subject.\n- Read books and make an dedicated notes for them.\n- Listen podcasts but capture them inside a \"subject specific\" note or \"Map of Concept\" note or a note tagged #areas. Because making notes from podcasts can be tedious as they're not as well structured as books for consumption.(Whose merit is debatable.)\n- #areas are basically \"Map of Concept\" notes but I have recently come to the realization that its better to maintain them [Nikita Voloboev style](https://wiki.nikiv.dev/) but with heavy usage of transclusion and backlinking.\n  - \"Resources\" should be first processed and then mentioned inside the note, otherwise they should be left in inbox.\n\n### Gotta capture 'em all\n\n- Hog whatever information tickles your pickle([anything that gratifies one's intellectual curiosity](https://news.ycombinator.com/newsguidelines.html)).\n- [[swipes]] are interesting/useful bits of... [[quotes|swipes.quotes]], [[excerpts|swipes.excerpts]], [[sayings|swipes.sayings]], [[phrases|swipes.phrases]]. Essentially, ideas, opinions that are swiped off from [[others|resources.people]].\n- Make no distinction between \"your\" ideas and ideas of \"others\", because if you vibe with an idea; it's already yours.\n- But also remember \"If you've time to consume, you've time to produce.\".\n- Use [raindrop.io](https://raindrop.io) to manage your URL bookmarks.\n- If you need to bookmark a webpage or an article all together, use [MarkDownload](https://chrome.google.com/webstore/detail/markdownload-markdown-web/pcmpcfapbekmbjjkdalcgopdkipoggdi?hl=en-GB) to rip the entire page. Let's call it a [[webmark|inbox.webmark]]; it belong in the `/inbox`.\n- Similar process is employed for capturing tweets using [tweet-to-markdown](https://github.com/kbravh/tweet-to-markdown) and it also belongs in the `/inbox`.\n\n### Don't force evolution\n\n- Let your second brain evolve at it's own pace.\n- The structure should never be _too_ rigid because its meant to take form by itself.\n\n### Noise & Signal\n\n- While capturing ideas left and right is recommended, make sure you're not harming your periods of focus.\n- Have impenetrable focus periods (use Pomodoro method) where you only care about the work on hand and nothing else.\n\n### Why do any of this?\n\n- Because I can't remember everything - there's a lot of information around that interests me and there isn't enough working memory installed in me.\n- So, I make notes - to remember, to create, to meditate, to think.\n- A bodybuilder's portfolio is their body - my portfolio is my wiki.\n- Not only am I making - whatever I know - tangible by writing it down. I know exactly where to look if I ever forget something.\n- I am at the beginning of my learning adventures. When I look back at it, I will know where I came from and how my thoughts evolved over time.\n- Plus, its really fun to nerd out.\n\n## Structure of this wiki\n\n- [[slipbox.Ontology]] explains the structure of this wiki and the tags, backlinks used in it.\n- Dendron takes care of the structure and hierarchy(mostly), but I insist on using tags for backwards compatibility.\n\n## Quicklinks\n\n- [[About me|archive.about]]\n- [Github](https://github.com/zubayrrr)\n- [Twitter](https://twitter.com/zoobhalu)\n- [Blog](https://zubayrali.in)\n- [Guestbook](https://www.yourworldoftext.com/~zubayrali/)\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{},"templateHierarchy":"template","insertNote":{"initialValue":"templates"}},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"Dendron"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableHandlebarTemplates":true,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false,"enableSmartRefs":true},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"theme":"dark","enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Noetic Noggin","description":"Personal Wiki / Digital Garden","author":"Zubayr Ali","twitter":"zoobhalu"},"github":{"enableEditLink":false,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"siteUrl":"localhost:3000","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}