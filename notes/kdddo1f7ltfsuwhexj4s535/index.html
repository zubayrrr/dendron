<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><title>HDFS</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal Wiki / Digital Garden"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="zoobhalu"/><meta name="twitter:creator" content="zoobhalu"/><meta property="og:title" content="HDFS"/><meta property="og:description" content="Personal Wiki / Digital Garden"/><meta property="og:url" content="localhost:3000/notes/kdddo1f7ltfsuwhexj4s535/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="Invalid DateTime"/><meta property="article:modified_time" content="5/23/2022"/><link rel="canonical" href="localhost:3000/notes/kdddo1f7ltfsuwhexj4s535/"/><meta name="next-head-count" content="17"/><link rel="preload" href="/_next/static/css/cc2307f6fd3a2fec.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cc2307f6fd3a2fec.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-709abf7ab5f510de.js" defer=""></script><script src="/_next/static/chunks/framework-bb5c596eafb42b22.js" defer=""></script><script src="/_next/static/chunks/main-c4b0e551a2150d17.js" defer=""></script><script src="/_next/static/chunks/pages/_app-62c5b93605efada7.js" defer=""></script><script src="/_next/static/chunks/78-13ae6acd5ce7ca5b.js" defer=""></script><script src="/_next/static/chunks/373-2f3879190a46a3d9.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bid%5D-69449972c2a725d8.js" defer=""></script><script src="/_next/static/4oDSInv8WeDX6cVSprjyl/_buildManifest.js" defer=""></script><script src="/_next/static/4oDSInv8WeDX6cVSprjyl/_ssgManifest.js" defer=""></script><script src="/_next/static/4oDSInv8WeDX6cVSprjyl/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout site-layout" style="margin-top:64px"><section class="ant-layout site-layout"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><section class="ant-layout side-layout-main" style="max-width:1200px;display:initial"><main class="ant-layout-content main-content" role="main" style="padding:0 24px"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="hdfs"><a aria-hidden="true" class="anchor-heading" href="#hdfs"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>HDFS</h1>
<ul>
<li>Traditional filesystems are not designed for large files and fast streaming reads hence HDFS was introduced.</li>
<li>It is designed for "write once/read many" uses cases.</li>
<li>It is a distributed/spread out filesystem.</li>
<li>Requires low coherency/concurrency overhead
<ul>
<li>No random file writes, one user writing at a time. (can be a restriction/constraint)</li>
</ul>
</li>
<li>HDFS takes files and stripes them across different servers and then allows us to scan those files in parallel at the same time. Each chunk/slice is on a different server.</li>
<li>The goal is to <strong>move computation to data</strong>.</li>
<li>Uses a converged data-computation model; slice data file and place pieces on multiple computational nodes/servers.</li>
</ul>
<h3 id="namenodes-and-datanodes"><a aria-hidden="true" class="anchor-heading" href="#namenodes-and-datanodes"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>NameNodes and Datanodes</h3>
<ul>
<li>HDFS uses a director/worker model.</li>
<li>The director or the daemon is called the NameNode and acts as a metadata server (data about data) or "data traffic cop".</li>
<li>NameNode keeps metadata in memory for performance.</li>
<li>Provides a single filesystem namespace that is managed by the NameNode.</li>
<li>The workers are DataNode(s)(at least one); Data is stored on these nodes.</li>
<li>A secondary NameNode checkpoints NameNode metadata to disk, but does not provide failover.</li>
</ul>
<h3 id="hdfs-roles"><a aria-hidden="true" class="anchor-heading" href="#hdfs-roles"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>HDFS Roles</h3>
<ul>
<li>
<p>User client-layer talks with NameNode(transparent to user). Often called as <strong>Edge Node</strong></p>
</li>
<li>
<p>NameNode keeps track of metadata and uses DataNodes for actual data storage.</p>
</li>
<li>
<p>Data flows from client node directly to/from DataNodes.</p>
</li>
<li>
<p>Secondary NameNode checkpoints the metadata to disk but is not failover.</p>
</li>
<li>
<p><img src="https://raw.githubusercontent.com/zubayrrr/twiki/main/bin/image.zt918wn73hk.png"></p>
</li>
</ul>
<h3 id="the-hdfs-file-system-namespace"><a aria-hidden="true" class="anchor-heading" href="#the-hdfs-file-system-namespace"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>The HDFS File System Namespace</h3>
<ul>
<li>Provides a hierarchical file system with files and directories.</li>
<li>Namespace path starts with <code>/</code> and provides user directories.</li>
<li>Users can create, remove, move, rename and copy files.</li>
<li>There are no <span class="underline">random reads or writes only appends</span>.</li>
<li>User must access HDFS through <a href="/notes/85w31vcdf3bjnm0yxh72ygf">Hadoop</a> client layer, not directly on DataNodes or NFSv3</li>
<li>Features include: High Availability(multiple NameNodes), Federation(spread namespace across multiple NameNodes), Snapshots(instant read-only point-in-time copies), and NFSv3 mounts.</li>
</ul>
<h3 id="replication-in-hdfs"><a aria-hidden="true" class="anchor-heading" href="#replication-in-hdfs"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Replication in HDFS</h3>
<ul>
<li>Data is replicated (default is 3 copies).</li>
<li>Replication is used for both redundancy and better availability on busy clusters.</li>
<li>At 3x repliaction a 320 MB file requires 1 GB of space in HDFS.</li>
<li>HDFS V3 supports erasure coding for achived data (reduces storage space).</li>
</ul>
<p><img src="https://raw.githubusercontent.com/zubayrrr/twiki/main/bin/image.1eqf63vf4xu.png"></p>
<h3 id="how-the-user-sees-hdfs"><a aria-hidden="true" class="anchor-heading" href="#how-the-user-sees-hdfs"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>How The User "Sees" HDFS</h3>
<ul>
<li>HDFS is a separate file system from the host server(edge node).</li>
<li>All Hadoop processing happens in HDFS, but first:
<ul>
<li>1. Data must be moved to edge node/server from user's source (local or web/cloud).</li>
<li>2. Data must be moved from edge node to HDFS using put and get client commands.</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/zubayrrr/twiki/main/bin/image.yxr0gacpr2.png"></p>
<hr>
<h2 id="hdfs-cli"><a aria-hidden="true" class="anchor-heading" href="#hdfs-cli"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>HDFS cli</h2>
<h4 id="make-a-dir-in-hdfs"><a aria-hidden="true" class="anchor-heading" href="#make-a-dir-in-hdfs"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Make a dir in HDFS</h4>
<p><code>hdfs dfs -mkdir stuff</code> will create a dir in home dir(since no path was supplied, /users/hands-on) named "stuff"</p>
<h4 id="copy-files-to-hdfs"><a aria-hidden="true" class="anchor-heading" href="#copy-files-to-hdfs"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Copy files to HDFS</h4>
<p><code>hdfs dfs -put war-and-peace.txt stuff</code></p>
<h4 id="copy-files-from-hdfs"><a aria-hidden="true" class="anchor-heading" href="#copy-files-from-hdfs"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Copy files from HDFS</h4>
<p>Copy files back to your local file system</p>
<p><code>hdfs dfs -get stuff/war-and-peace.txt war-and-peace-copy.txt</code></p>
<h4 id="copy-files-within-hdfs"><a aria-hidden="true" class="anchor-heading" href="#copy-files-within-hdfs"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Copy files within HDFS</h4>
<p><code>hdfs dfs -cp stuff/war-and-peace.txt copy-of-war-and-peace.txt</code></p>
<h4 id="delete-files-within-hdfs"><a aria-hidden="true" class="anchor-heading" href="#delete-files-within-hdfs"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Delete files within HDFS</h4>
<p><code>hdfs dfs -rm copy-of-war-and-peace.txt</code></p>
<h4 id="list-files-on-hdfs-userhands-on"><a aria-hidden="true" class="anchor-heading" href="#list-files-on-hdfs-userhands-on"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>List files on HDFS (/user/hands-on)</h4>
<p><code>hdfs dfs -ls</code></p>
<h4 id="delete-a-dir-in-hdfs"><a aria-hidden="true" class="anchor-heading" href="#delete-a-dir-in-hdfs"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Delete a dir in HDFS</h4>
<p><code>hdfs dfs -rm -r stuff</code></p>
<p>to skip the trash(if trash collection is enabled use <code>-skipTrash</code>)</p>
<h2 id="hdfs-web-interface"><a aria-hidden="true" class="anchor-heading" href="#hdfs-web-interface"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>HDFS Web Interface</h2>
<p>The HDFS web interaface: <code>http://127.0.0.1:50070</code>
The <a href="/notes/6k7g4x7ws565lditv1n8hxm">YARN</a> Jobs web interface: <code>http://127.0.0.1:8088</code>
Zeppelin Web Notebook: <code>http://127.0.0.9995</code></p>
<p>The HDFS web interace also features "Browse the file system" under the "Utilities" dropdown menu.</p>
<hr>
<strong>Backlinks</strong>
<ul>
<li><a href="/notes/f2kecna72pmc7re3wh1ugk4">Apache Spark</a></li>
<li><a href="/notes/s5t9uscswvpo3p6gebui1ea">Big Data</a></li>
<li><a href="/notes/2fz1tdl3yy2s78wdmo7ql56">Data Engineering Roadmap</a></li>
<li><a href="/notes/lz322a84xc913sor5r5c71u">Data Warehouse</a></li>
<li><a href="/notes/ffhm4kotv5wbd139ml9ch44">ETL</a></li>
<li><a href="/notes/30isnfzmqrvmmiii03d0chj">Hive</a></li>
<li><a href="/notes/j6kfx6ziqg91r356nur9cwy">MapReduce</a></li>
<li><a href="/notes/2vn2g9mhmi624b83rl5se0k">RDD</a></li>
</ul></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#namenodes-and-datanodes" title="NameNodes and Datanodes">NameNodes and Datanodes</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#hdfs-roles" title="HDFS Roles">HDFS Roles</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#the-hdfs-file-system-namespace" title="The HDFS File System Namespace">The HDFS File System Namespace</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#replication-in-hdfs" title="Replication in HDFS">Replication in HDFS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#how-the-user-sees-hdfs" title="How The User &quot;Sees&quot; HDFS">How The User &quot;Sees&quot; HDFS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#hdfs-cli" title="HDFS cli">HDFS cli</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#make-a-dir-in-hdfs" title="Make a dir in HDFS">Make a dir in HDFS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#copy-files-to-hdfs" title="Copy files to HDFS">Copy files to HDFS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#copy-files-from-hdfs" title="Copy files from HDFS">Copy files from HDFS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#copy-files-within-hdfs" title="Copy files within HDFS">Copy files within HDFS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#delete-files-within-hdfs" title="Delete files within HDFS">Delete files within HDFS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#list-files-on-hdfs-userhands-on" title="List files on HDFS (/user/hands-on)">List files on HDFS (/user/hands-on)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#delete-a-dir-in-hdfs" title="Delete a dir in HDFS">Delete a dir in HDFS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#hdfs-web-interface" title="HDFS Web Interface">HDFS Web Interface</a></div></div></div></div></div></div></div></div></div></main><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></section></section></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"kdddo1f7ltfsuwhexj4s535","title":"HDFS","desc":"","updated":1653305294717,"created":20211110214903030,"custom":{},"fname":"devlog.hdfs","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Dendron"},"contentHash":"31131bac5341e38e758be6d64308a310","links":[{"type":"wiki","from":{"fname":"devlog.hdfs","id":"kdddo1f7ltfsuwhexj4s535","vaultName":"Dendron"},"value":"devlog.hadoop","alias":"devlog.hadoop","position":{"start":{"line":38,"column":33,"offset":1922},"end":{"line":38,"column":50,"offset":1939},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.hadoop"}},{"type":"wiki","from":{"fname":"devlog.hdfs","id":"kdddo1f7ltfsuwhexj4s535","vaultName":"Dendron"},"value":"devlog.yarn","alias":"devlog.yarn","position":{"start":{"line":98,"column":5,"offset":3743},"end":{"line":98,"column":20,"offset":3758},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"devlog.yarn"}},{"from":{"fname":"devlog.apache spark","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":70,"column":70,"offset":2047},"end":{"line":70,"column":85,"offset":2062},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.apache spark","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":70,"column":105,"offset":2082},"end":{"line":70,"column":120,"offset":2097},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.apache spark","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":159,"column":77,"offset":6313},"end":{"line":159,"column":92,"offset":6328},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.big data","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":61,"column":46,"offset":2261},"end":{"line":61,"column":61,"offset":2276},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.big data","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":101,"column":5,"offset":4732},"end":{"line":101,"column":20,"offset":4747},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.big data","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":125,"column":5,"offset":6015},"end":{"line":125,"column":20,"offset":6030},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.data engineering roadmap","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":17,"column":3,"offset":540},"end":{"line":17,"column":18,"offset":555},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.data warehouse","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":45,"column":102,"offset":2697},"end":{"line":45,"column":117,"offset":2712},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.etl","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":39,"column":51,"offset":980},"end":{"line":39,"column":66,"offset":995},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.hive","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":18,"column":21,"offset":985},"end":{"line":18,"column":36,"offset":1000},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.hive","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":20,"column":1,"offset":1025},"end":{"line":20,"column":16,"offset":1040},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.mapreduce","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":15,"column":67,"offset":524},"end":{"line":15,"column":82,"offset":539},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.mapreduce","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":57,"column":81,"offset":2386},"end":{"line":57,"column":96,"offset":2401},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"},{"from":{"fname":"devlog.rdd","vaultName":"Dendron"},"type":"backlink","position":{"start":{"line":8,"column":77,"offset":148},"end":{"line":8,"column":92,"offset":163},"indent":[]},"value":"devlog.hdfs","alias":"devlog.hdfs"}],"anchors":{"namenodes-and-datanodes":{"type":"header","text":"NameNodes and Datanodes","value":"namenodes-and-datanodes","line":17,"column":0,"depth":3},"hdfs-roles":{"type":"header","text":"HDFS Roles","value":"hdfs-roles","line":26,"column":0,"depth":3},"the-hdfs-file-system-namespace":{"type":"header","text":"The HDFS File System Namespace","value":"the-hdfs-file-system-namespace","line":38,"column":0,"depth":3},"replication-in-hdfs":{"type":"header","text":"Replication in HDFS","value":"replication-in-hdfs","line":47,"column":0,"depth":3},"how-the-user-sees-hdfs":{"type":"header","text":"How The User \"Sees\" HDFS","value":"how-the-user-sees-hdfs","line":56,"column":0,"depth":3},"hdfs-cli":{"type":"header","text":"HDFS cli","value":"hdfs-cli","line":67,"column":0,"depth":2},"make-a-dir-in-hdfs":{"type":"header","text":"Make a dir in HDFS","value":"make-a-dir-in-hdfs","line":69,"column":0,"depth":4},"copy-files-to-hdfs":{"type":"header","text":"Copy files to HDFS","value":"copy-files-to-hdfs","line":73,"column":0,"depth":4},"copy-files-from-hdfs":{"type":"header","text":"Copy files from HDFS","value":"copy-files-from-hdfs","line":77,"column":0,"depth":4},"copy-files-within-hdfs":{"type":"header","text":"Copy files within HDFS","value":"copy-files-within-hdfs","line":83,"column":0,"depth":4},"delete-files-within-hdfs":{"type":"header","text":"Delete files within HDFS","value":"delete-files-within-hdfs","line":87,"column":0,"depth":4},"list-files-on-hdfs-userhands-on":{"type":"header","text":"List files on HDFS (/user/hands-on)","value":"list-files-on-hdfs-userhands-on","line":91,"column":0,"depth":4},"delete-a-dir-in-hdfs":{"type":"header","text":"Delete a dir in HDFS","value":"delete-a-dir-in-hdfs","line":95,"column":0,"depth":4},"hdfs-web-interface":{"type":"header","text":"HDFS Web Interface","value":"hdfs-web-interface","line":101,"column":0,"depth":2}},"children":[],"parent":"9gtn7g40cvqui0sifl1s7t5","data":{}},"body":"\u003ch1 id=\"hdfs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#hdfs\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eHDFS\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eTraditional filesystems are not designed for large files and fast streaming reads hence HDFS was introduced.\u003c/li\u003e\n\u003cli\u003eIt is designed for \"write once/read many\" uses cases.\u003c/li\u003e\n\u003cli\u003eIt is a distributed/spread out filesystem.\u003c/li\u003e\n\u003cli\u003eRequires low coherency/concurrency overhead\n\u003cul\u003e\n\u003cli\u003eNo random file writes, one user writing at a time. (can be a restriction/constraint)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eHDFS takes files and stripes them across different servers and then allows us to scan those files in parallel at the same time. Each chunk/slice is on a different server.\u003c/li\u003e\n\u003cli\u003eThe goal is to \u003cstrong\u003emove computation to data\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eUses a converged data-computation model; slice data file and place pieces on multiple computational nodes/servers.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"namenodes-and-datanodes\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#namenodes-and-datanodes\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eNameNodes and Datanodes\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eHDFS uses a director/worker model.\u003c/li\u003e\n\u003cli\u003eThe director or the daemon is called the NameNode and acts as a metadata server (data about data) or \"data traffic cop\".\u003c/li\u003e\n\u003cli\u003eNameNode keeps metadata in memory for performance.\u003c/li\u003e\n\u003cli\u003eProvides a single filesystem namespace that is managed by the NameNode.\u003c/li\u003e\n\u003cli\u003eThe workers are DataNode(s)(at least one); Data is stored on these nodes.\u003c/li\u003e\n\u003cli\u003eA secondary NameNode checkpoints NameNode metadata to disk, but does not provide failover.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"hdfs-roles\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#hdfs-roles\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eHDFS Roles\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUser client-layer talks with NameNode(transparent to user). Often called as \u003cstrong\u003eEdge Node\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNameNode keeps track of metadata and uses DataNodes for actual data storage.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eData flows from client node directly to/from DataNodes.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSecondary NameNode checkpoints the metadata to disk but is not failover.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zubayrrr/twiki/main/bin/image.zt918wn73hk.png\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"the-hdfs-file-system-namespace\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#the-hdfs-file-system-namespace\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eThe HDFS File System Namespace\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eProvides a hierarchical file system with files and directories.\u003c/li\u003e\n\u003cli\u003eNamespace path starts with \u003ccode\u003e/\u003c/code\u003e and provides user directories.\u003c/li\u003e\n\u003cli\u003eUsers can create, remove, move, rename and copy files.\u003c/li\u003e\n\u003cli\u003eThere are no \u003cspan class=\"underline\"\u003erandom reads or writes only appends\u003c/span\u003e.\u003c/li\u003e\n\u003cli\u003eUser must access HDFS through \u003ca href=\"/notes/85w31vcdf3bjnm0yxh72ygf\"\u003eHadoop\u003c/a\u003e client layer, not directly on DataNodes or NFSv3\u003c/li\u003e\n\u003cli\u003eFeatures include: High Availability(multiple NameNodes), Federation(spread namespace across multiple NameNodes), Snapshots(instant read-only point-in-time copies), and NFSv3 mounts.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"replication-in-hdfs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#replication-in-hdfs\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eReplication in HDFS\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eData is replicated (default is 3 copies).\u003c/li\u003e\n\u003cli\u003eReplication is used for both redundancy and better availability on busy clusters.\u003c/li\u003e\n\u003cli\u003eAt 3x repliaction a 320 MB file requires 1 GB of space in HDFS.\u003c/li\u003e\n\u003cli\u003eHDFS V3 supports erasure coding for achived data (reduces storage space).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zubayrrr/twiki/main/bin/image.1eqf63vf4xu.png\"\u003e\u003c/p\u003e\n\u003ch3 id=\"how-the-user-sees-hdfs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#how-the-user-sees-hdfs\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eHow The User \"Sees\" HDFS\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eHDFS is a separate file system from the host server(edge node).\u003c/li\u003e\n\u003cli\u003eAll Hadoop processing happens in HDFS, but first:\n\u003cul\u003e\n\u003cli\u003e1. Data must be moved to edge node/server from user's source (local or web/cloud).\u003c/li\u003e\n\u003cli\u003e2. Data must be moved from edge node to HDFS using put and get client commands.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/zubayrrr/twiki/main/bin/image.yxr0gacpr2.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"hdfs-cli\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#hdfs-cli\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eHDFS cli\u003c/h2\u003e\n\u003ch4 id=\"make-a-dir-in-hdfs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#make-a-dir-in-hdfs\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eMake a dir in HDFS\u003c/h4\u003e\n\u003cp\u003e\u003ccode\u003ehdfs dfs -mkdir stuff\u003c/code\u003e will create a dir in home dir(since no path was supplied, /users/hands-on) named \"stuff\"\u003c/p\u003e\n\u003ch4 id=\"copy-files-to-hdfs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#copy-files-to-hdfs\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eCopy files to HDFS\u003c/h4\u003e\n\u003cp\u003e\u003ccode\u003ehdfs dfs -put war-and-peace.txt stuff\u003c/code\u003e\u003c/p\u003e\n\u003ch4 id=\"copy-files-from-hdfs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#copy-files-from-hdfs\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eCopy files from HDFS\u003c/h4\u003e\n\u003cp\u003eCopy files back to your local file system\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ehdfs dfs -get stuff/war-and-peace.txt war-and-peace-copy.txt\u003c/code\u003e\u003c/p\u003e\n\u003ch4 id=\"copy-files-within-hdfs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#copy-files-within-hdfs\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eCopy files within HDFS\u003c/h4\u003e\n\u003cp\u003e\u003ccode\u003ehdfs dfs -cp stuff/war-and-peace.txt copy-of-war-and-peace.txt\u003c/code\u003e\u003c/p\u003e\n\u003ch4 id=\"delete-files-within-hdfs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#delete-files-within-hdfs\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eDelete files within HDFS\u003c/h4\u003e\n\u003cp\u003e\u003ccode\u003ehdfs dfs -rm copy-of-war-and-peace.txt\u003c/code\u003e\u003c/p\u003e\n\u003ch4 id=\"list-files-on-hdfs-userhands-on\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#list-files-on-hdfs-userhands-on\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eList files on HDFS (/user/hands-on)\u003c/h4\u003e\n\u003cp\u003e\u003ccode\u003ehdfs dfs -ls\u003c/code\u003e\u003c/p\u003e\n\u003ch4 id=\"delete-a-dir-in-hdfs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#delete-a-dir-in-hdfs\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eDelete a dir in HDFS\u003c/h4\u003e\n\u003cp\u003e\u003ccode\u003ehdfs dfs -rm -r stuff\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eto skip the trash(if trash collection is enabled use \u003ccode\u003e-skipTrash\u003c/code\u003e)\u003c/p\u003e\n\u003ch2 id=\"hdfs-web-interface\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#hdfs-web-interface\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eHDFS Web Interface\u003c/h2\u003e\n\u003cp\u003eThe HDFS web interaface: \u003ccode\u003ehttp://127.0.0.1:50070\u003c/code\u003e\nThe \u003ca href=\"/notes/6k7g4x7ws565lditv1n8hxm\"\u003eYARN\u003c/a\u003e Jobs web interface: \u003ccode\u003ehttp://127.0.0.1:8088\u003c/code\u003e\nZeppelin Web Notebook: \u003ccode\u003ehttp://127.0.0.9995\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThe HDFS web interace also features \"Browse the file system\" under the \"Utilities\" dropdown menu.\u003c/p\u003e\n\u003chr\u003e\n\u003cstrong\u003eBacklinks\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/notes/f2kecna72pmc7re3wh1ugk4\"\u003eApache Spark\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/s5t9uscswvpo3p6gebui1ea\"\u003eBig Data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/2fz1tdl3yy2s78wdmo7ql56\"\u003eData Engineering Roadmap\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/lz322a84xc913sor5r5c71u\"\u003eData Warehouse\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/ffhm4kotv5wbd139ml9ch44\"\u003eETL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/30isnfzmqrvmmiii03d0chj\"\u003eHive\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/j6kfx6ziqg91r356nur9cwy\"\u003eMapReduce\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/2vn2g9mhmi624b83rl5se0k\"\u003eRDD\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","noteIndex":{"id":"3nfl4nvv516muyzozhcwrw8","title":"/root","desc":"","updated":1655559901157,"created":1637610830605,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Dendron"},"contentHash":"581715455a6f0f7a699209e8521b4acf","links":[{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"archive.about","alias":"my","position":{"start":{"line":4,"column":9,"offset":37},"end":{"line":4,"column":29,"offset":57},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"archive.about"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"tags.areas","alias":"#areas","position":{"start":{"line":20,"column":111,"offset":1051},"end":{"line":20,"column":117,"offset":1057},"indent":[]},"xvault":false,"to":{"fname":"tags.areas"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"tags.areas","alias":"#areas","position":{"start":{"line":21,"column":3,"offset":1198},"end":{"line":21,"column":9,"offset":1204},"indent":[]},"xvault":false,"to":{"fname":"tags.areas"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"swipes","alias":"swipes","position":{"start":{"line":27,"column":3,"offset":1724},"end":{"line":27,"column":13,"offset":1734},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"swipes"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"swipes.quotes","alias":"quotes","position":{"start":{"line":27,"column":48,"offset":1769},"end":{"line":27,"column":72,"offset":1793},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"swipes.quotes"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"swipes.excerpts","alias":"excerpts","position":{"start":{"line":27,"column":74,"offset":1795},"end":{"line":27,"column":102,"offset":1823},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"swipes.excerpts"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"swipes.sayings","alias":"sayings","position":{"start":{"line":27,"column":104,"offset":1825},"end":{"line":27,"column":130,"offset":1851},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"swipes.sayings"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"swipes.phrases","alias":"phrases","position":{"start":{"line":27,"column":132,"offset":1853},"end":{"line":27,"column":158,"offset":1879},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"swipes.phrases"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"resources.people","alias":"others","position":{"start":{"line":27,"column":214,"offset":1935},"end":{"line":27,"column":241,"offset":1962},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"resources.people"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"inbox.webmark","alias":"webmark","position":{"start":{"line":31,"column":235,"offset":2463},"end":{"line":31,"column":260,"offset":2488},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"inbox.webmark"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"slipbox.Ontology","alias":"slipbox.Ontology","position":{"start":{"line":55,"column":3,"offset":3735},"end":{"line":55,"column":23,"offset":3755},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"slipbox.Ontology"}},{"type":"wiki","from":{"fname":"root","id":"3nfl4nvv516muyzozhcwrw8","vaultName":"Dendron"},"value":"archive.about","alias":"About me","position":{"start":{"line":60,"column":3,"offset":3963},"end":{"line":60,"column":29,"offset":3989},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"archive.about"}}],"anchors":{"welcome-to-noetic-noggin":{"type":"header","text":"Welcome to Noetic Noggin","value":"welcome-to-noetic-noggin","line":8,"column":0,"depth":1},"principles":{"type":"header","text":"Principles","value":"principles","line":18,"column":0,"depth":2},"all-notes-should-be-relative-to-me":{"type":"header","text":"All notes should be relative to me.","value":"all-notes-should-be-relative-to-me","line":20,"column":0,"depth":3},"gotta-capture-em-all":{"type":"header","text":"Gotta capture 'em all","value":"gotta-capture-em-all","line":30,"column":0,"depth":3},"dont-force-evolution":{"type":"header","text":"Don't force evolution","value":"dont-force-evolution","line":40,"column":0,"depth":3},"noise--signal":{"type":"header","text":"Noise \u0026 Signal","value":"noise--signal","line":45,"column":0,"depth":3},"why-do-any-of-this":{"type":"header","text":"Why do any of this?","value":"why-do-any-of-this","line":50,"column":0,"depth":3},"structure-of-this-wiki":{"type":"header","text":"Structure of this wiki","value":"structure-of-this-wiki","line":59,"column":0,"depth":2},"quicklinks":{"type":"header","text":"Quicklinks","value":"quicklinks","line":64,"column":0,"depth":2}},"children":["0yay2om15bsg2li2p6qgux7","05c4nnjqa92zx11ld6o0ytn","9gtn7g40cvqui0sifl1s7t5","ftbd1hknsd3ocd7jao26tn3","a1kmkdbpclaz5p6sykaw6kc","z121gkmqfo09m8r7jgnpfgn","gkqrr7xbt18xhi93dmjrwzj","ja2x4lrgejr9o9wvit0bd0d","luv39odkfibx3wdosvigwvy","vtvk3bi6o72w58oima9xzf3","yy652kvqrkfn9ipk07m40h4"],"parent":null,"data":{},"body":"\n# Welcome to Noetic Noggin\n\nThis is [[my|archive.about]] personal wiki and a commonplace book; notes by me, for me.\n\nðŸš§ Permanently under construction ðŸš§\n\n![](https://res.cloudinary.com/zubayr/image/upload/v1658499909/wiki/ajevkuyebljlxiblyst2.png)\n\nThis wiki was made possible with [dendron.so](https://dendron.so) and [obisidian.md](https://obsidian.md). Stored on [Github Repository](https://github.com/zubayrrr/dendron) and hosted on [Netlify](https://netlify.com) for free.\n\n## Principles\n\n### All notes should be relative to me.\n\n- All notes in principle are written for me; what I know about a subject, how I feel about a particular thing.\n- Opinions are fine as long as I feel strong epistemic confidence in the given opinion.\n- Don't over explain a note if it's not necessary, remember, these notes are for you and are relative to whatever knowledge you posses about the subject.\n- Read books and make an dedicated notes for them.\n- Listen podcasts but capture them inside a \"subject specific\" note or \"Map of Concept\" note or a note tagged #areas. Because making notes from podcasts can be tedious as they're not as well structured as books for consumption.(Whose merit is debatable.)\n- #areas are basically \"Map of Concept\" notes but I have recently come to the realization that its better to maintain them [Nikita Voloboev style](https://wiki.nikiv.dev/) but with heavy usage of transclusion and backlinking.\n  - \"Resources\" should be first processed and then mentioned inside the note, otherwise they should be left in inbox.\n\n### Gotta capture 'em all\n\n- Hog whatever information tickles your pickle([anything that gratifies one's intellectual curiosity](https://news.ycombinator.com/newsguidelines.html)).\n- [[swipes]] are interesting/useful bits of... [[quotes|swipes.quotes]], [[excerpts|swipes.excerpts]], [[sayings|swipes.sayings]], [[phrases|swipes.phrases]]. Essentially, ideas, opinions that are swiped off from [[others|resources.people]].\n- Make no distinction between \"your\" ideas and ideas of \"others\", because if you vibe with an idea; it's already yours.\n- But also remember \"If you've time to consume, you've time to produce.\".\n- Use [raindrop.io](https://raindrop.io) to manage your URL bookmarks.\n- If you need to bookmark a webpage or an article all together, use [MarkDownload](https://chrome.google.com/webstore/detail/markdownload-markdown-web/pcmpcfapbekmbjjkdalcgopdkipoggdi?hl=en-GB) to rip the entire page. Let's call it a [[webmark|inbox.webmark]]; it belong in the `/inbox`.\n- Similar process is employed for capturing tweets using [tweet-to-markdown](https://github.com/kbravh/tweet-to-markdown) and it also belongs in the `/inbox`.\n\n### Don't force evolution\n\n- Let your second brain evolve at it's own pace.\n- The structure should never be _too_ rigid because its meant to take form by itself.\n\n### Noise \u0026 Signal\n\n- While capturing ideas left and right is recommended, make sure you're not harming your periods of focus.\n- Have impenetrable focus periods (use Pomodoro method) where you only care about the work on hand and nothing else.\n\n### Why do any of this?\n\n- Because I can't remember everything - there's a lot of information around that interests me and there isn't enough working memory installed in me.\n- So, I make notes - to remember, to create, to meditate, to think.\n- A bodybuilder's portfolio is their body - my portfolio is my wiki.\n- Not only am I making - whatever I know - tangible by writing it down. I know exactly where to look if I ever forget something.\n- I am at the beginning of my learning adventures. When I look back at it, I will know where I came from and how my thoughts evolved over time.\n- Plus, its really fun to nerd out.\n\n## Structure of this wiki\n\n- [[slipbox.Ontology]] explains the structure of this wiki and the tags, backlinks used in it.\n- Dendron takes care of the structure and hierarchy(mostly), but I insist on using tags for backwards compatibility.\n\n## Quicklinks\n\n- [[About me|archive.about]]\n- [Github](https://github.com/zubayrrr)\n- [Twitter](https://twitter.com/zoobhalu)\n- [Blog](https://zubayrali.in)\n- [Guestbook](https://www.yourworldoftext.com/~zubayrali/)\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{},"templateHierarchy":"template","insertNote":{"initialValue":"templates"}},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"Dendron"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableHandlebarTemplates":true,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false,"enableSmartRefs":true},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"theme":"dark","enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Noetic Noggin","description":"Personal Wiki / Digital Garden","author":"Zubayr Ali","twitter":"zoobhalu"},"github":{"enableEditLink":false,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"siteUrl":"localhost:3000","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"kdddo1f7ltfsuwhexj4s535"},"buildId":"4oDSInv8WeDX6cVSprjyl","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>